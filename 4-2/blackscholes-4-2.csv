Learning Rate, Epochs, Sampling Rate, test data fraction, max layers, max neurons, Error
0.1,1,0.1,0.1,4,2,0.995981500
0.1,2,0.1,0.1,4,2,0.981514610
0.1,3,0.1,0.1,4,2,0.919704610
0.1,4,0.1,0.1,4,2,0.706004260
0.1,5,0.1,0.1,4,2,0.626622770
0.1,6,0.1,0.1,4,2,0.627181100
0.1,7,0.1,0.1,4,2,0.635430830
0.1,8,0.1,0.1,4,2,0.622019330
0.1,9,0.1,0.1,4,2,0.636732170
0.1,10,0.1,0.1,4,2,0.634924880
0.1,11,0.1,0.1,4,2,0.640217040
0.1,12,0.1,0.1,4,2,0.629866980
0.1,13,0.1,0.1,4,2,0.631131410
0.1,14,0.1,0.1,4,2,0.641377390
0.1,15,0.1,0.1,4,2,0.632748960
0.1,16,0.1,0.1,4,2,0.637343940
0.1,17,0.1,0.1,4,2,0.629735080
0.1,18,0.1,0.1,4,2,0.638989720
0.1,19,0.1,0.1,4,2,0.637979320
0.1,20,0.1,0.1,4,2,0.633832520
0.1,21,0.1,0.1,4,2,0.637750370
0.1,22,0.1,0.1,4,2,0.633033070
0.1,23,0.1,0.1,4,2,0.636400060
0.1,24,0.1,0.1,4,2,0.640975540
0.1,25,0.1,0.1,4,2,0.636662330
0.1,26,0.1,0.1,4,2,0.638788820
0.1,27,0.1,0.1,4,2,0.641924380
0.1,28,0.1,0.1,4,2,0.636741520
0.1,29,0.1,0.1,4,2,0.635691960
0.1,30,0.1,0.1,4,2,0.645442850
0.1,31,0.1,0.1,4,2,0.633857690
0.1,32,0.1,0.1,4,2,0.639285420
0.1,33,0.1,0.1,4,2,0.627331230
0.1,34,0.1,0.1,4,2,0.631373720
0.1,35,0.1,0.1,4,2,0.644100660
0.1,36,0.1,0.1,4,2,0.633658560
0.1,37,0.1,0.1,4,2,0.630796010
0.1,38,0.1,0.1,4,2,0.632521170
0.1,39,0.1,0.1,4,2,0.636426890
0.1,40,0.1,0.1,4,2,0.626967510
0.1,41,0.1,0.1,4,2,0.633886800
0.1,42,0.1,0.1,4,2,0.633791090
0.1,43,0.1,0.1,4,2,0.635715960
0.1,44,0.1,0.1,4,2,0.615381980
0.1,45,0.1,0.1,4,2,0.635410940
0.1,46,0.1,0.1,4,2,0.626609660
0.1,47,0.1,0.1,4,2,0.632634520
0.1,48,0.1,0.1,4,2,0.626848780
0.1,49,0.1,0.1,4,2,0.629735760
0.1,50,0.1,0.1,4,2,0.627885910
0.1,51,0.1,0.1,4,2,0.620532550
0.1,52,0.1,0.1,4,2,0.621289200
0.1,53,0.1,0.1,4,2,0.624551100
0.1,54,0.1,0.1,4,2,0.625075660
0.1,55,0.1,0.1,4,2,0.637187180
0.1,56,0.1,0.1,4,2,0.627460600
0.1,57,0.1,0.1,4,2,0.621869470
0.1,58,0.1,0.1,4,2,0.619366110
0.1,59,0.1,0.1,4,2,0.628834860
0.1,60,0.1,0.1,4,2,0.618767890
0.1,61,0.1,0.1,4,2,0.626120560
0.1,62,0.1,0.1,4,2,0.628183410
0.1,63,0.1,0.1,4,2,0.622716650
0.1,64,0.1,0.1,4,2,0.616891660
0.1,65,0.1,0.1,4,2,0.616835720
0.1,66,0.1,0.1,4,2,0.618413450
0.1,67,0.1,0.1,4,2,0.618964440
0.1,68,0.1,0.1,4,2,0.613310380
0.1,69,0.1,0.1,4,2,0.615396900
0.1,70,0.1,0.1,4,2,0.615204370
0.1,71,0.1,0.1,4,2,0.620756550
0.1,72,0.1,0.1,4,2,0.616009400
0.1,73,0.1,0.1,4,2,0.609045790
0.1,74,0.1,0.1,4,2,0.613027550
0.1,75,0.1,0.1,4,2,0.606237160
0.1,76,0.1,0.1,4,2,0.622246330
0.1,77,0.1,0.1,4,2,0.612878080
0.1,78,0.1,0.1,4,2,0.609434790
0.1,79,0.1,0.1,4,2,0.608646660
0.1,80,0.1,0.1,4,2,0.619075450
0.1,81,0.1,0.1,4,2,0.612620490
0.1,82,0.1,0.1,4,2,0.612901160
0.1,83,0.1,0.1,4,2,0.612056850
0.1,84,0.1,0.1,4,2,0.614498250
0.1,85,0.1,0.1,4,2,0.605114810
0.1,86,0.1,0.1,4,2,0.612316710
0.1,87,0.1,0.1,4,2,0.616089600
0.1,88,0.1,0.1,4,2,0.613753430
0.1,89,0.1,0.1,4,2,0.601064680
0.1,90,0.1,0.1,4,2,0.616401640
0.1,91,0.1,0.1,4,2,0.601714340
0.1,92,0.1,0.1,4,2,0.611578940
0.1,93,0.1,0.1,4,2,0.600890330
0.1,94,0.1,0.1,4,2,0.593982900
0.1,95,0.1,0.1,4,2,0.607827420
0.1,96,0.1,0.1,4,2,0.609008280
0.1,97,0.1,0.1,4,2,0.606972230
0.1,98,0.1,0.1,4,2,0.608125970
0.1,99,0.1,0.1,4,2,0.599208240
0.1,100,0.1,0.1,4,2,0.613518540
