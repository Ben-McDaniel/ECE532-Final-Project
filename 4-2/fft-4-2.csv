Learning Rate, Epochs, Sampling Rate, test data fraction, max layers, max neurons, Error
0.1,1,0.1,0.1,4,2,0.955907820
0.1,2,0.1,0.1,4,2,0.939795990
0.1,3,0.1,0.1,4,2,0.915065690
0.1,4,0.1,0.1,4,2,0.918178190
0.1,5,0.1,0.1,4,2,0.914284490
0.1,6,0.1,0.1,4,2,0.915166090
0.1,7,0.1,0.1,4,2,0.918617400
0.1,8,0.1,0.1,4,2,0.916223350
0.1,9,0.1,0.1,4,2,0.913424420
0.1,10,0.1,0.1,4,2,0.914602130
0.1,11,0.1,0.1,4,2,0.905774330
0.1,12,0.1,0.1,4,2,0.917852420
0.1,13,0.1,0.1,4,2,0.887534490
0.1,14,0.1,0.1,4,2,0.887970940
0.1,15,0.1,0.1,4,2,0.879272490
0.1,16,0.1,0.1,4,2,0.854209340
0.1,17,0.1,0.1,4,2,0.821359600
0.1,18,0.1,0.1,4,2,0.903835250
0.1,19,0.1,0.1,4,2,0.819014740
0.1,20,0.1,0.1,4,2,0.911263030
0.1,21,0.1,0.1,4,2,0.776293000
0.1,22,0.1,0.1,4,2,0.870995390
0.1,23,0.1,0.1,4,2,0.844509150
0.1,24,0.1,0.1,4,2,0.846379970
0.1,25,0.1,0.1,4,2,0.883300810
0.1,26,0.1,0.1,4,2,0.791895530
0.1,27,0.1,0.1,4,2,0.783654890
0.1,28,0.1,0.1,4,2,0.804236610
0.1,29,0.1,0.1,4,2,0.766474790
0.1,30,0.1,0.1,4,2,0.857201410
0.1,31,0.1,0.1,4,2,0.787292970
0.1,32,0.1,0.1,4,2,0.842679630
0.1,33,0.1,0.1,4,2,0.773796030
0.1,34,0.1,0.1,4,2,0.779160020
0.1,35,0.1,0.1,4,2,0.843736510
0.1,36,0.1,0.1,4,2,0.802114260
0.1,37,0.1,0.1,4,2,0.697197580
0.1,38,0.1,0.1,4,2,0.769998050
0.1,39,0.1,0.1,4,2,0.680971750
0.1,40,0.1,0.1,4,2,0.815512660
0.1,41,0.1,0.1,4,2,0.748227770
0.1,42,0.1,0.1,4,2,0.869525760
0.1,43,0.1,0.1,4,2,0.698004310
0.1,44,0.1,0.1,4,2,0.753199500
0.1,45,0.1,0.1,4,2,0.710609180
0.1,46,0.1,0.1,4,2,0.715278580
0.1,47,0.1,0.1,4,2,0.688932360
0.1,48,0.1,0.1,4,2,0.685201580
0.1,49,0.1,0.1,4,2,0.702999130
0.1,50,0.1,0.1,4,2,0.705268670
0.1,51,0.1,0.1,4,2,0.634450210
0.1,52,0.1,0.1,4,2,0.809307570
0.1,53,0.1,0.1,4,2,0.718479690
0.1,54,0.1,0.1,4,2,0.671397760
0.1,55,0.1,0.1,4,2,0.659964230
0.1,56,0.1,0.1,4,2,0.615104790
0.1,57,0.1,0.1,4,2,0.652460310
0.1,58,0.1,0.1,4,2,0.606164300
0.1,59,0.1,0.1,4,2,0.654603970
0.1,60,0.1,0.1,4,2,0.702408240
0.1,61,0.1,0.1,4,2,0.622119460
0.1,62,0.1,0.1,4,2,0.635358780
0.1,63,0.1,0.1,4,2,0.653973830
0.1,64,0.1,0.1,4,2,0.587834750
0.1,65,0.1,0.1,4,2,0.601250710
0.1,66,0.1,0.1,4,2,0.647220000
0.1,67,0.1,0.1,4,2,0.657153850
0.1,68,0.1,0.1,4,2,0.557247120
0.1,69,0.1,0.1,4,2,0.630433010
0.1,70,0.1,0.1,4,2,0.654280560
0.1,71,0.1,0.1,4,2,0.627911230
0.1,72,0.1,0.1,4,2,0.633175430
0.1,73,0.1,0.1,4,2,0.577465290
0.1,74,0.1,0.1,4,2,0.591078280
0.1,75,0.1,0.1,4,2,0.719059160
0.1,76,0.1,0.1,4,2,0.567346220
0.1,77,0.1,0.1,4,2,0.623986440
0.1,78,0.1,0.1,4,2,0.599639800
0.1,79,0.1,0.1,4,2,0.562729030
0.1,80,0.1,0.1,4,2,0.593914900
0.1,81,0.1,0.1,4,2,0.587649270
0.1,82,0.1,0.1,4,2,0.646703060
0.1,83,0.1,0.1,4,2,0.635507630
0.1,84,0.1,0.1,4,2,0.487963170
0.1,85,0.1,0.1,4,2,0.555659410
0.1,86,0.1,0.1,4,2,0.609697220
0.1,87,0.1,0.1,4,2,0.526517360
0.1,88,0.1,0.1,4,2,0.591684270
0.1,89,0.1,0.1,4,2,0.587707000
0.1,90,0.1,0.1,4,2,0.576614490
0.1,91,0.1,0.1,4,2,0.600926600
0.1,92,0.1,0.1,4,2,0.562508880
0.1,93,0.1,0.1,4,2,0.591984990
0.1,94,0.1,0.1,4,2,0.603622440
0.1,95,0.1,0.1,4,2,0.579263240
0.1,96,0.1,0.1,4,2,0.615758970
0.1,97,0.1,0.1,4,2,0.481513050
0.1,98,0.1,0.1,4,2,0.569733560
0.1,99,0.1,0.1,4,2,0.608750990
0.1,100,0.1,0.1,4,2,0.410063650
