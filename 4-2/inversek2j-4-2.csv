Learning Rate, Epochs, Sampling Rate, test data fraction, max layers, max neurons, Error
0.1,1,0.1,0.1,4,2,0.771398220
0.1,2,0.1,0.1,4,2,0.633972240
0.1,3,0.1,0.1,4,2,0.539003080
0.1,4,0.1,0.1,4,2,0.506699370
0.1,5,0.1,0.1,4,2,0.496158810
0.1,6,0.1,0.1,4,2,0.500529860
0.1,7,0.1,0.1,4,2,0.484444780
0.1,8,0.1,0.1,4,2,0.429581000
0.1,9,0.1,0.1,4,2,0.406549290
0.1,10,0.1,0.1,4,2,0.377422950
0.1,11,0.1,0.1,4,2,0.404560330
0.1,12,0.1,0.1,4,2,0.374553080
0.1,13,0.1,0.1,4,2,0.385412710
0.1,14,0.1,0.1,4,2,0.373729880
0.1,15,0.1,0.1,4,2,0.373457400
0.1,16,0.1,0.1,4,2,0.370824610
0.1,17,0.1,0.1,4,2,0.376915960
0.1,18,0.1,0.1,4,2,0.367084870
0.1,19,0.1,0.1,4,2,0.363925270
0.1,20,0.1,0.1,4,2,0.368026440
0.1,21,0.1,0.1,4,2,0.367925360
0.1,22,0.1,0.1,4,2,0.366382980
0.1,23,0.1,0.1,4,2,0.364698240
0.1,24,0.1,0.1,4,2,0.367859470
0.1,25,0.1,0.1,4,2,0.368993280
0.1,26,0.1,0.1,4,2,0.362914440
0.1,27,0.1,0.1,4,2,0.363603790
0.1,28,0.1,0.1,4,2,0.369541400
0.1,29,0.1,0.1,4,2,0.379430610
0.1,30,0.1,0.1,4,2,0.362205730
0.1,31,0.1,0.1,4,2,0.367303990
0.1,32,0.1,0.1,4,2,0.368219940
0.1,33,0.1,0.1,4,2,0.366372140
0.1,34,0.1,0.1,4,2,0.360896920
0.1,35,0.1,0.1,4,2,0.363437320
0.1,36,0.1,0.1,4,2,0.365812220
0.1,37,0.1,0.1,4,2,0.360950370
0.1,38,0.1,0.1,4,2,0.356899230
0.1,39,0.1,0.1,4,2,0.363080260
0.1,40,0.1,0.1,4,2,0.352591380
0.1,41,0.1,0.1,4,2,0.360836680
0.1,42,0.1,0.1,4,2,0.350932850
0.1,43,0.1,0.1,4,2,0.357796760
0.1,44,0.1,0.1,4,2,0.357334450
0.1,45,0.1,0.1,4,2,0.344475660
0.1,46,0.1,0.1,4,2,0.354831680
0.1,47,0.1,0.1,4,2,0.356855060
0.1,48,0.1,0.1,4,2,0.353044670
0.1,49,0.1,0.1,4,2,0.360138810
0.1,50,0.1,0.1,4,2,0.352104750
0.1,51,0.1,0.1,4,2,0.342428700
0.1,52,0.1,0.1,4,2,0.348812690
0.1,53,0.1,0.1,4,2,0.348537530
0.1,54,0.1,0.1,4,2,0.351222910
0.1,55,0.1,0.1,4,2,0.345047370
0.1,56,0.1,0.1,4,2,0.350803520
0.1,57,0.1,0.1,4,2,0.331953520
0.1,58,0.1,0.1,4,2,0.339572300
0.1,59,0.1,0.1,4,2,0.342093600
0.1,60,0.1,0.1,4,2,0.347006760
0.1,61,0.1,0.1,4,2,0.350599310
0.1,62,0.1,0.1,4,2,0.347248320
0.1,63,0.1,0.1,4,2,0.339621610
0.1,64,0.1,0.1,4,2,0.348430930
0.1,65,0.1,0.1,4,2,0.339519560
0.1,66,0.1,0.1,4,2,0.336795260
0.1,67,0.1,0.1,4,2,0.342877160
0.1,68,0.1,0.1,4,2,0.340942700
0.1,69,0.1,0.1,4,2,0.336313510
0.1,70,0.1,0.1,4,2,0.337888750
0.1,71,0.1,0.1,4,2,0.334675530
0.1,72,0.1,0.1,4,2,0.344596370
0.1,73,0.1,0.1,4,2,0.326140290
0.1,74,0.1,0.1,4,2,0.336775100
0.1,75,0.1,0.1,4,2,0.334547730
0.1,76,0.1,0.1,4,2,0.336648200
0.1,77,0.1,0.1,4,2,0.338177030
0.1,78,0.1,0.1,4,2,0.341738250
0.1,79,0.1,0.1,4,2,0.331862900
0.1,80,0.1,0.1,4,2,0.335635390
0.1,81,0.1,0.1,4,2,0.327451640
0.1,82,0.1,0.1,4,2,0.335445120
0.1,83,0.1,0.1,4,2,0.332957750
0.1,84,0.1,0.1,4,2,0.338984810
0.1,85,0.1,0.1,4,2,0.331980480
0.1,86,0.1,0.1,4,2,0.324154000
0.1,87,0.1,0.1,4,2,0.318704160
0.1,88,0.1,0.1,4,2,0.305788150
0.1,89,0.1,0.1,4,2,0.342222660
0.1,90,0.1,0.1,4,2,0.331216580
0.1,91,0.1,0.1,4,2,0.331590900
0.1,92,0.1,0.1,4,2,0.328405040
0.1,93,0.1,0.1,4,2,0.334222260
0.1,94,0.1,0.1,4,2,0.340948800
0.1,95,0.1,0.1,4,2,0.335663830
0.1,96,0.1,0.1,4,2,0.322465640
0.1,97,0.1,0.1,4,2,0.316472290
0.1,98,0.1,0.1,4,2,0.328678880
0.1,99,0.1,0.1,4,2,0.331355410
0.1,100,0.1,0.1,4,2,0.325681200
