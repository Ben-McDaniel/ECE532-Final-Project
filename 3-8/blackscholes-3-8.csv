Learning Rate, Epochs, Sampling Rate, test data fraction, max layers, max neurons, Error
0.1,1,0.1,0.1,3,8,0.974101470
0.1,2,0.1,0.1,3,8,0.703563910
0.1,3,0.1,0.1,3,8,0.651278580
0.1,4,0.1,0.1,3,8,0.625466480
0.1,5,0.1,0.1,3,8,0.635119780
0.1,6,0.1,0.1,3,8,0.629686050
0.1,7,0.1,0.1,3,8,0.644166720
0.1,8,0.1,0.1,3,8,0.640876860
0.1,9,0.1,0.1,3,8,0.623640640
0.1,10,0.1,0.1,3,8,0.635393530
0.1,11,0.1,0.1,3,8,0.631851650
0.1,12,0.1,0.1,3,8,0.627192950
0.1,13,0.1,0.1,3,8,0.622563110
0.1,14,0.1,0.1,3,8,0.629103440
0.1,15,0.1,0.1,3,8,0.630677650
0.1,16,0.1,0.1,3,8,0.635231140
0.1,17,0.1,0.1,3,8,0.635942050
0.1,18,0.1,0.1,3,8,0.637506410
0.1,19,0.1,0.1,3,8,0.638909930
0.1,20,0.1,0.1,3,8,0.636215490
0.1,21,0.1,0.1,3,8,0.639810530
0.1,22,0.1,0.1,3,8,0.637512720
0.1,23,0.1,0.1,3,8,0.640806740
0.1,24,0.1,0.1,3,8,0.637127060
0.1,25,0.1,0.1,3,8,0.634733940
0.1,26,0.1,0.1,3,8,0.645475300
0.1,27,0.1,0.1,3,8,0.640624220
0.1,28,0.1,0.1,3,8,0.632063760
0.1,29,0.1,0.1,3,8,0.626474320
0.1,30,0.1,0.1,3,8,0.628336940
0.1,31,0.1,0.1,3,8,0.638779380
0.1,32,0.1,0.1,3,8,0.625074690
0.1,33,0.1,0.1,3,8,0.634877700
0.1,34,0.1,0.1,3,8,0.641033610
0.1,35,0.1,0.1,3,8,0.605438250
0.1,36,0.1,0.1,3,8,0.626215370
0.1,37,0.1,0.1,3,8,0.612657820
0.1,38,0.1,0.1,3,8,0.622484510
0.1,39,0.1,0.1,3,8,0.620453340
0.1,40,0.1,0.1,3,8,0.621771910
0.1,41,0.1,0.1,3,8,0.625862360
0.1,42,0.1,0.1,3,8,0.627558120
0.1,43,0.1,0.1,3,8,0.621416190
0.1,44,0.1,0.1,3,8,0.630364040
0.1,45,0.1,0.1,3,8,0.628706350
0.1,46,0.1,0.1,3,8,0.627795020
0.1,47,0.1,0.1,3,8,0.619833390
0.1,48,0.1,0.1,3,8,0.622920060
0.1,49,0.1,0.1,3,8,0.622776270
0.1,50,0.1,0.1,3,8,0.629988000
0.1,51,0.1,0.1,3,8,0.619940250
0.1,52,0.1,0.1,3,8,0.632208230
0.1,53,0.1,0.1,3,8,0.622570710
0.1,54,0.1,0.1,3,8,0.611319680
0.1,55,0.1,0.1,3,8,0.623164370
0.1,56,0.1,0.1,3,8,0.619914100
0.1,57,0.1,0.1,3,8,0.628538150
0.1,58,0.1,0.1,3,8,0.618622250
0.1,59,0.1,0.1,3,8,0.623840080
0.1,60,0.1,0.1,3,8,0.627947040
0.1,61,0.1,0.1,3,8,0.624188940
0.1,62,0.1,0.1,3,8,0.618997600
0.1,63,0.1,0.1,3,8,0.627993240
0.1,64,0.1,0.1,3,8,0.618014480
0.1,65,0.1,0.1,3,8,0.618738110
0.1,66,0.1,0.1,3,8,0.605717950
0.1,67,0.1,0.1,3,8,0.619255490
0.1,68,0.1,0.1,3,8,0.623118990
0.1,69,0.1,0.1,3,8,0.618972110
0.1,70,0.1,0.1,3,8,0.616843700
0.1,71,0.1,0.1,3,8,0.620920960
0.1,72,0.1,0.1,3,8,0.627436110
0.1,73,0.1,0.1,3,8,0.618768360
0.1,74,0.1,0.1,3,8,0.612690600
0.1,75,0.1,0.1,3,8,0.613293950
0.1,76,0.1,0.1,3,8,0.617793650
0.1,77,0.1,0.1,3,8,0.600076170
0.1,78,0.1,0.1,3,8,0.610012770
0.1,79,0.1,0.1,3,8,0.616747520
0.1,80,0.1,0.1,3,8,0.605632500
0.1,81,0.1,0.1,3,8,0.604771610
0.1,82,0.1,0.1,3,8,0.619250430
0.1,83,0.1,0.1,3,8,0.608363360
0.1,84,0.1,0.1,3,8,0.604237950
0.1,85,0.1,0.1,3,8,0.603746560
0.1,86,0.1,0.1,3,8,0.600639550
0.1,87,0.1,0.1,3,8,0.613034770
0.1,88,0.1,0.1,3,8,0.607740970
0.1,89,0.1,0.1,3,8,0.608018960
0.1,90,0.1,0.1,3,8,0.595620950
0.1,91,0.1,0.1,3,8,0.616115380
0.1,92,0.1,0.1,3,8,0.608464800
0.1,93,0.1,0.1,3,8,0.611483900
0.1,94,0.1,0.1,3,8,0.610390010
0.1,95,0.1,0.1,3,8,0.587086450
0.1,96,0.1,0.1,3,8,0.599810090
0.1,97,0.1,0.1,3,8,0.578131160
0.1,98,0.1,0.1,3,8,0.604979460
0.1,99,0.1,0.1,3,8,0.593488230
0.1,100,0.1,0.1,3,8,0.599095340
