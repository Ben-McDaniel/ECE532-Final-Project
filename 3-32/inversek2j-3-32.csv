Learning Rate, Epochs, Sampling Rate, test data fraction, max layers, max neurons, Error
0.1,1,0.1,0.1,3,32,0.520643440
0.1,2,0.1,0.1,3,32,0.521360000
0.1,3,0.1,0.1,3,32,0.503275750
0.1,4,0.1,0.1,3,32,0.499515690
0.1,5,0.1,0.1,3,32,0.475889170
0.1,6,0.1,0.1,3,32,0.421348310
0.1,7,0.1,0.1,3,32,0.425724570
0.1,8,0.1,0.1,3,32,0.377667160
0.1,9,0.1,0.1,3,32,0.380658630
0.1,10,0.1,0.1,3,32,0.372079980
0.1,11,0.1,0.1,3,32,0.371100420
0.1,12,0.1,0.1,3,32,0.372356110
0.1,13,0.1,0.1,3,32,0.376044180
0.1,14,0.1,0.1,3,32,0.366554070
0.1,15,0.1,0.1,3,32,0.362811150
0.1,16,0.1,0.1,3,32,0.370019520
0.1,17,0.1,0.1,3,32,0.360319800
0.1,18,0.1,0.1,3,32,0.360283020
0.1,19,0.1,0.1,3,32,0.357723110
0.1,20,0.1,0.1,3,32,0.354514920
0.1,21,0.1,0.1,3,32,0.355537310
0.1,22,0.1,0.1,3,32,0.351863050
0.1,23,0.1,0.1,3,32,0.348005900
0.1,24,0.1,0.1,3,32,0.359948630
0.1,25,0.1,0.1,3,32,0.349705600
0.1,26,0.1,0.1,3,32,0.343715560
0.1,27,0.1,0.1,3,32,0.341460160
0.1,28,0.1,0.1,3,32,0.339673680
0.1,29,0.1,0.1,3,32,0.339792050
0.1,30,0.1,0.1,3,32,0.337927260
0.1,31,0.1,0.1,3,32,0.331847880
0.1,32,0.1,0.1,3,32,0.328815360
0.1,33,0.1,0.1,3,32,0.336193580
0.1,34,0.1,0.1,3,32,0.330487830
0.1,35,0.1,0.1,3,32,0.334622940
0.1,36,0.1,0.1,3,32,0.330143750
0.1,37,0.1,0.1,3,32,0.312130940
0.1,38,0.1,0.1,3,32,0.327471010
0.1,39,0.1,0.1,3,32,0.332443560
0.1,40,0.1,0.1,3,32,0.318805230
0.1,41,0.1,0.1,3,32,0.332362460
0.1,42,0.1,0.1,3,32,0.328471410
0.1,43,0.1,0.1,3,32,0.313429850
0.1,44,0.1,0.1,3,32,0.297154500
0.1,45,0.1,0.1,3,32,0.306439810
0.1,46,0.1,0.1,3,32,0.310896570
0.1,47,0.1,0.1,3,32,0.301341260
0.1,48,0.1,0.1,3,32,0.293380570
0.1,49,0.1,0.1,3,32,0.287886700
0.1,50,0.1,0.1,3,32,0.287837540
0.1,51,0.1,0.1,3,32,0.302854000
0.1,52,0.1,0.1,3,32,0.285634790
0.1,53,0.1,0.1,3,32,0.279513080
0.1,54,0.1,0.1,3,32,0.314280440
0.1,55,0.1,0.1,3,32,0.284476980
0.1,56,0.1,0.1,3,32,0.280009890
0.1,57,0.1,0.1,3,32,0.286485320
0.1,58,0.1,0.1,3,32,0.270148220
0.1,59,0.1,0.1,3,32,0.221888410
0.1,60,0.1,0.1,3,32,0.289924740
0.1,61,0.1,0.1,3,32,0.277551700
0.1,62,0.1,0.1,3,32,0.281702310
0.1,63,0.1,0.1,3,32,0.248053380
0.1,64,0.1,0.1,3,32,0.255476240
0.1,65,0.1,0.1,3,32,0.257912890
0.1,66,0.1,0.1,3,32,0.263900640
0.1,67,0.1,0.1,3,32,0.258873180
0.1,68,0.1,0.1,3,32,0.245473990
0.1,69,0.1,0.1,3,32,0.231504850
0.1,70,0.1,0.1,3,32,0.231251450
0.1,71,0.1,0.1,3,32,0.232844280
0.1,72,0.1,0.1,3,32,0.242394670
0.1,73,0.1,0.1,3,32,0.253994570
0.1,74,0.1,0.1,3,32,0.231849590
0.1,75,0.1,0.1,3,32,0.238968800
0.1,76,0.1,0.1,3,32,0.204468840
0.1,77,0.1,0.1,3,32,0.246430110
0.1,78,0.1,0.1,3,32,0.224044550
0.1,79,0.1,0.1,3,32,0.230051110
0.1,80,0.1,0.1,3,32,0.197150370
0.1,81,0.1,0.1,3,32,0.245777230
0.1,82,0.1,0.1,3,32,0.205140890
0.1,83,0.1,0.1,3,32,0.213739100
0.1,84,0.1,0.1,3,32,0.241854010
0.1,85,0.1,0.1,3,32,0.217895710
0.1,86,0.1,0.1,3,32,0.191281740
0.1,87,0.1,0.1,3,32,0.211516650
0.1,88,0.1,0.1,3,32,0.218735860
0.1,89,0.1,0.1,3,32,0.209280130
0.1,90,0.1,0.1,3,32,0.195751920
0.1,91,0.1,0.1,3,32,0.186338910
0.1,92,0.1,0.1,3,32,0.199614010
0.1,93,0.1,0.1,3,32,0.188731750
0.1,94,0.1,0.1,3,32,0.198791780
0.1,95,0.1,0.1,3,32,0.200015740
0.1,96,0.1,0.1,3,32,0.158832400
0.1,97,0.1,0.1,3,32,0.190293000
0.1,98,0.1,0.1,3,32,0.167283800
0.1,99,0.1,0.1,3,32,0.164197830
0.1,100,0.1,0.1,3,32,0.158882390
