Learning Rate, Epochs, Sampling Rate, test data fraction, max layers, max neurons, Error
0.1,1,0.1,0.1,3,16,0.834246460
0.1,2,0.1,0.1,3,16,0.643562410
0.1,3,0.1,0.1,3,16,0.636746440
0.1,4,0.1,0.1,3,16,0.634746320
0.1,5,0.1,0.1,3,16,0.620750590
0.1,6,0.1,0.1,3,16,0.649108710
0.1,7,0.1,0.1,3,16,0.639592200
0.1,8,0.1,0.1,3,16,0.625812790
0.1,9,0.1,0.1,3,16,0.643747110
0.1,10,0.1,0.1,3,16,0.648395470
0.1,11,0.1,0.1,3,16,0.643821770
0.1,12,0.1,0.1,3,16,0.630350340
0.1,13,0.1,0.1,3,16,0.628256670
0.1,14,0.1,0.1,3,16,0.635431960
0.1,15,0.1,0.1,3,16,0.634033540
0.1,16,0.1,0.1,3,16,0.632821120
0.1,17,0.1,0.1,3,16,0.646593670
0.1,18,0.1,0.1,3,16,0.642323980
0.1,19,0.1,0.1,3,16,0.641998830
0.1,20,0.1,0.1,3,16,0.640052350
0.1,21,0.1,0.1,3,16,0.636985960
0.1,22,0.1,0.1,3,16,0.639260190
0.1,23,0.1,0.1,3,16,0.633056630
0.1,24,0.1,0.1,3,16,0.638241440
0.1,25,0.1,0.1,3,16,0.629766540
0.1,26,0.1,0.1,3,16,0.640822110
0.1,27,0.1,0.1,3,16,0.639150580
0.1,28,0.1,0.1,3,16,0.631862220
0.1,29,0.1,0.1,3,16,0.637953540
0.1,30,0.1,0.1,3,16,0.637418790
0.1,31,0.1,0.1,3,16,0.630820430
0.1,32,0.1,0.1,3,16,0.636524150
0.1,33,0.1,0.1,3,16,0.635687640
0.1,34,0.1,0.1,3,16,0.628915610
0.1,35,0.1,0.1,3,16,0.626922170
0.1,36,0.1,0.1,3,16,0.621888420
0.1,37,0.1,0.1,3,16,0.616699470
0.1,38,0.1,0.1,3,16,0.616069840
0.1,39,0.1,0.1,3,16,0.618431110
0.1,40,0.1,0.1,3,16,0.639530520
0.1,41,0.1,0.1,3,16,0.629653510
0.1,42,0.1,0.1,3,16,0.621659040
0.1,43,0.1,0.1,3,16,0.633809060
0.1,44,0.1,0.1,3,16,0.624470970
0.1,45,0.1,0.1,3,16,0.629473750
0.1,46,0.1,0.1,3,16,0.626428170
0.1,47,0.1,0.1,3,16,0.625688330
0.1,48,0.1,0.1,3,16,0.626283870
0.1,49,0.1,0.1,3,16,0.612619650
0.1,50,0.1,0.1,3,16,0.627406880
0.1,51,0.1,0.1,3,16,0.625003530
0.1,52,0.1,0.1,3,16,0.616347670
0.1,53,0.1,0.1,3,16,0.623776050
0.1,54,0.1,0.1,3,16,0.623022550
0.1,55,0.1,0.1,3,16,0.628311380
0.1,56,0.1,0.1,3,16,0.629778440
0.1,57,0.1,0.1,3,16,0.623062370
0.1,58,0.1,0.1,3,16,0.620747220
0.1,59,0.1,0.1,3,16,0.609559930
0.1,60,0.1,0.1,3,16,0.626786880
0.1,61,0.1,0.1,3,16,0.627266700
0.1,62,0.1,0.1,3,16,0.617719150
0.1,63,0.1,0.1,3,16,0.618320080
0.1,64,0.1,0.1,3,16,0.624554040
0.1,65,0.1,0.1,3,16,0.621846110
0.1,66,0.1,0.1,3,16,0.625329320
0.1,67,0.1,0.1,3,16,0.624288670
0.1,68,0.1,0.1,3,16,0.614113280
0.1,69,0.1,0.1,3,16,0.619535850
0.1,70,0.1,0.1,3,16,0.619524270
0.1,71,0.1,0.1,3,16,0.616246520
0.1,72,0.1,0.1,3,16,0.621857960
0.1,73,0.1,0.1,3,16,0.603272830
0.1,74,0.1,0.1,3,16,0.614337160
0.1,75,0.1,0.1,3,16,0.602977860
0.1,76,0.1,0.1,3,16,0.620536750
0.1,77,0.1,0.1,3,16,0.609849460
0.1,78,0.1,0.1,3,16,0.621177980
0.1,79,0.1,0.1,3,16,0.608295010
0.1,80,0.1,0.1,3,16,0.619668940
0.1,81,0.1,0.1,3,16,0.617552840
0.1,82,0.1,0.1,3,16,0.605914900
0.1,83,0.1,0.1,3,16,0.614628000
0.1,84,0.1,0.1,3,16,0.616368380
0.1,85,0.1,0.1,3,16,0.615676210
0.1,86,0.1,0.1,3,16,0.618700760
0.1,87,0.1,0.1,3,16,0.611926510
0.1,88,0.1,0.1,3,16,0.612006040
0.1,89,0.1,0.1,3,16,0.603857870
0.1,90,0.1,0.1,3,16,0.593953880
0.1,91,0.1,0.1,3,16,0.599355070
0.1,92,0.1,0.1,3,16,0.585432790
0.1,93,0.1,0.1,3,16,0.585020980
0.1,94,0.1,0.1,3,16,0.615526750
0.1,95,0.1,0.1,3,16,0.606593410
0.1,96,0.1,0.1,3,16,0.604682950
0.1,97,0.1,0.1,3,16,0.589107790
0.1,98,0.1,0.1,3,16,0.580208240
0.1,99,0.1,0.1,3,16,0.576692620
0.1,100,0.1,0.1,3,16,0.603462320
