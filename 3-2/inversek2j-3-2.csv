Learning Rate, Epochs, Sampling Rate, test data fraction, max layers, max neurons, Error
0.1,1,0.1,0.1,3,2,0.792212600
0.1,2,0.1,0.1,3,2,0.650987750
0.1,3,0.1,0.1,3,2,0.541154080
0.1,4,0.1,0.1,3,2,0.503878190
0.1,5,0.1,0.1,3,2,0.502144560
0.1,6,0.1,0.1,3,2,0.484528320
0.1,7,0.1,0.1,3,2,0.455852420
0.1,8,0.1,0.1,3,2,0.431349680
0.1,9,0.1,0.1,3,2,0.411063010
0.1,10,0.1,0.1,3,2,0.393274060
0.1,11,0.1,0.1,3,2,0.389484070
0.1,12,0.1,0.1,3,2,0.382138840
0.1,13,0.1,0.1,3,2,0.372539290
0.1,14,0.1,0.1,3,2,0.376184100
0.1,15,0.1,0.1,3,2,0.371052340
0.1,16,0.1,0.1,3,2,0.372861730
0.1,17,0.1,0.1,3,2,0.366030570
0.1,18,0.1,0.1,3,2,0.370324360
0.1,19,0.1,0.1,3,2,0.364499290
0.1,20,0.1,0.1,3,2,0.373615210
0.1,21,0.1,0.1,3,2,0.373204510
0.1,22,0.1,0.1,3,2,0.366745710
0.1,23,0.1,0.1,3,2,0.367476920
0.1,24,0.1,0.1,3,2,0.368524170
0.1,25,0.1,0.1,3,2,0.364156800
0.1,26,0.1,0.1,3,2,0.366377180
0.1,27,0.1,0.1,3,2,0.369480820
0.1,28,0.1,0.1,3,2,0.370439840
0.1,29,0.1,0.1,3,2,0.368582650
0.1,30,0.1,0.1,3,2,0.363403610
0.1,31,0.1,0.1,3,2,0.368113440
0.1,32,0.1,0.1,3,2,0.365580040
0.1,33,0.1,0.1,3,2,0.370454860
0.1,34,0.1,0.1,3,2,0.361951780
0.1,35,0.1,0.1,3,2,0.365262610
0.1,36,0.1,0.1,3,2,0.359717570
0.1,37,0.1,0.1,3,2,0.366216320
0.1,38,0.1,0.1,3,2,0.361429930
0.1,39,0.1,0.1,3,2,0.365530920
0.1,40,0.1,0.1,3,2,0.355725830
0.1,41,0.1,0.1,3,2,0.361984350
0.1,42,0.1,0.1,3,2,0.357255820
0.1,43,0.1,0.1,3,2,0.356912930
0.1,44,0.1,0.1,3,2,0.352654530
0.1,45,0.1,0.1,3,2,0.357714410
0.1,46,0.1,0.1,3,2,0.350445080
0.1,47,0.1,0.1,3,2,0.345412940
0.1,48,0.1,0.1,3,2,0.354694310
0.1,49,0.1,0.1,3,2,0.346647650
0.1,50,0.1,0.1,3,2,0.351548010
0.1,51,0.1,0.1,3,2,0.351035100
0.1,52,0.1,0.1,3,2,0.353396960
0.1,53,0.1,0.1,3,2,0.351658350
0.1,54,0.1,0.1,3,2,0.346036080
0.1,55,0.1,0.1,3,2,0.346987090
0.1,56,0.1,0.1,3,2,0.348066460
0.1,57,0.1,0.1,3,2,0.343784910
0.1,58,0.1,0.1,3,2,0.345725480
0.1,59,0.1,0.1,3,2,0.338403720
0.1,60,0.1,0.1,3,2,0.341515730
0.1,61,0.1,0.1,3,2,0.345126730
0.1,62,0.1,0.1,3,2,0.341905000
0.1,63,0.1,0.1,3,2,0.334847360
0.1,64,0.1,0.1,3,2,0.340484160
0.1,65,0.1,0.1,3,2,0.343256780
0.1,66,0.1,0.1,3,2,0.338718460
0.1,67,0.1,0.1,3,2,0.335341930
0.1,68,0.1,0.1,3,2,0.329250850
0.1,69,0.1,0.1,3,2,0.345977910
0.1,70,0.1,0.1,3,2,0.341766400
0.1,71,0.1,0.1,3,2,0.336158200
0.1,72,0.1,0.1,3,2,0.346504170
0.1,73,0.1,0.1,3,2,0.339010940
0.1,74,0.1,0.1,3,2,0.336320720
0.1,75,0.1,0.1,3,2,0.346460660
0.1,76,0.1,0.1,3,2,0.331446490
0.1,77,0.1,0.1,3,2,0.338525080
0.1,78,0.1,0.1,3,2,0.331223140
0.1,79,0.1,0.1,3,2,0.339872700
0.1,80,0.1,0.1,3,2,0.333439750
0.1,81,0.1,0.1,3,2,0.332839490
0.1,82,0.1,0.1,3,2,0.337297990
0.1,83,0.1,0.1,3,2,0.331689150
0.1,84,0.1,0.1,3,2,0.325051340
0.1,85,0.1,0.1,3,2,0.338012960
0.1,86,0.1,0.1,3,2,0.333353860
0.1,87,0.1,0.1,3,2,0.316232120
0.1,88,0.1,0.1,3,2,0.333237390
0.1,89,0.1,0.1,3,2,0.339169680
0.1,90,0.1,0.1,3,2,0.329411680
0.1,91,0.1,0.1,3,2,0.335820990
0.1,92,0.1,0.1,3,2,0.331411120
0.1,93,0.1,0.1,3,2,0.333868390
0.1,94,0.1,0.1,3,2,0.337856990
0.1,95,0.1,0.1,3,2,0.320605470
0.1,96,0.1,0.1,3,2,0.323585230
0.1,97,0.1,0.1,3,2,0.328045640
0.1,98,0.1,0.1,3,2,0.330635450
0.1,99,0.1,0.1,3,2,0.328216630
0.1,100,0.1,0.1,3,2,0.330375400
