Learning Rate, Epochs, Sampling Rate, test data fraction, max layers, max neurons, Error
0.1,1,0.1,0.1,4,32,0.965379070
0.1,2,0.1,0.1,4,32,0.951826590
0.1,3,0.1,0.1,4,32,0.913592870
0.1,4,0.1,0.1,4,32,0.930180050
0.1,5,0.1,0.1,4,32,0.912199120
0.1,6,0.1,0.1,4,32,0.916806530
0.1,7,0.1,0.1,4,32,0.927089510
0.1,8,0.1,0.1,4,32,0.954200940
0.1,9,0.1,0.1,4,32,0.890281880
0.1,10,0.1,0.1,4,32,0.915827930
0.1,11,0.1,0.1,4,32,0.873135700
0.1,12,0.1,0.1,4,32,0.864011020
0.1,13,0.1,0.1,4,32,0.842250300
0.1,14,0.1,0.1,4,32,0.759295530
0.1,15,0.1,0.1,4,32,0.890907790
0.1,16,0.1,0.1,4,32,0.811713770
0.1,17,0.1,0.1,4,32,0.887123970
0.1,18,0.1,0.1,4,32,0.772571920
0.1,19,0.1,0.1,4,32,0.810115350
0.1,20,0.1,0.1,4,32,0.823784070
0.1,21,0.1,0.1,4,32,0.797073600
0.1,22,0.1,0.1,4,32,0.826800050
0.1,23,0.1,0.1,4,32,0.780102700
0.1,24,0.1,0.1,4,32,0.726002220
0.1,25,0.1,0.1,4,32,0.713649840
0.1,26,0.1,0.1,4,32,0.718546760
0.1,27,0.1,0.1,4,32,0.906627020
0.1,28,0.1,0.1,4,32,0.728384460
0.1,29,0.1,0.1,4,32,0.648285770
0.1,30,0.1,0.1,4,32,0.686122840
0.1,31,0.1,0.1,4,32,0.719830800
0.1,32,0.1,0.1,4,32,0.739378160
0.1,33,0.1,0.1,4,32,0.631029180
0.1,34,0.1,0.1,4,32,0.640568250
0.1,35,0.1,0.1,4,32,0.604017540
0.1,36,0.1,0.1,4,32,0.539793810
0.1,37,0.1,0.1,4,32,0.548619840
0.1,38,0.1,0.1,4,32,0.583247110
0.1,39,0.1,0.1,4,32,0.571708770
0.1,40,0.1,0.1,4,32,0.526978420
0.1,41,0.1,0.1,4,32,0.657006550
0.1,42,0.1,0.1,4,32,0.533423630
0.1,43,0.1,0.1,4,32,0.496134420
0.1,44,0.1,0.1,4,32,0.536721620
0.1,45,0.1,0.1,4,32,0.452120760
0.1,46,0.1,0.1,4,32,0.498095100
0.1,47,0.1,0.1,4,32,0.380849140
0.1,48,0.1,0.1,4,32,0.382515460
0.1,49,0.1,0.1,4,32,0.297329590
0.1,50,0.1,0.1,4,32,0.371599600
0.1,51,0.1,0.1,4,32,0.366438310
0.1,52,0.1,0.1,4,32,0.467969340
0.1,53,0.1,0.1,4,32,0.368608810
0.1,54,0.1,0.1,4,32,0.322207890
0.1,55,0.1,0.1,4,32,0.243070730
0.1,56,0.1,0.1,4,32,0.461090350
0.1,57,0.1,0.1,4,32,0.350578710
0.1,58,0.1,0.1,4,32,0.307919560
0.1,59,0.1,0.1,4,32,0.349931180
0.1,60,0.1,0.1,4,32,0.348953140
0.1,61,0.1,0.1,4,32,0.239260980
0.1,62,0.1,0.1,4,32,0.153657830
0.1,63,0.1,0.1,4,32,0.275522730
0.1,64,0.1,0.1,4,32,0.244737400
0.1,65,0.1,0.1,4,32,0.207768080
0.1,66,0.1,0.1,4,32,0.269472460
0.1,67,0.1,0.1,4,32,0.363732690
0.1,68,0.1,0.1,4,32,0.189105150
0.1,69,0.1,0.1,4,32,0.227713010
0.1,70,0.1,0.1,4,32,0.213551800
0.1,71,0.1,0.1,4,32,0.311371400
0.1,72,0.1,0.1,4,32,0.142427500
0.1,73,0.1,0.1,4,32,0.205753180
0.1,74,0.1,0.1,4,32,0.121655730
0.1,75,0.1,0.1,4,32,0.217653170
0.1,76,0.1,0.1,4,32,0.190954100
0.1,77,0.1,0.1,4,32,0.181666320
0.1,78,0.1,0.1,4,32,0.148420080
0.1,79,0.1,0.1,4,32,0.254262570
0.1,80,0.1,0.1,4,32,0.228041800
0.1,81,0.1,0.1,4,32,0.186222610
0.1,82,0.1,0.1,4,32,0.117297600
0.1,83,0.1,0.1,4,32,0.246900430
0.1,84,0.1,0.1,4,32,0.157812400
0.1,85,0.1,0.1,4,32,0.182506620
0.1,86,0.1,0.1,4,32,0.159942310
0.1,87,0.1,0.1,4,32,0.166439830
0.1,88,0.1,0.1,4,32,0.152755330
0.1,89,0.1,0.1,4,32,0.209489860
0.1,90,0.1,0.1,4,32,0.142109030
0.1,91,0.1,0.1,4,32,0.169594560
0.1,92,0.1,0.1,4,32,0.186692630
0.1,93,0.1,0.1,4,32,0.165437490
0.1,94,0.1,0.1,4,32,0.094109600
0.1,95,0.1,0.1,4,32,0.230338200
0.1,96,0.1,0.1,4,32,0.194732380
0.1,97,0.1,0.1,4,32,0.152005180
0.1,98,0.1,0.1,4,32,0.111233950
0.1,99,0.1,0.1,4,32,0.265070520
0.1,100,0.1,0.1,4,32,0.096898490
