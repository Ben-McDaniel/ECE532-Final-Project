Learning Rate, Epochs, Sampling Rate, test data fraction, max layers, max neurons, Error
0.1,1,0.1,0.1,3,64,0.954878520
0.1,2,0.1,0.1,3,64,0.950257380
0.1,3,0.1,0.1,3,64,0.948925820
0.1,4,0.1,0.1,3,64,0.933237030
0.1,5,0.1,0.1,3,64,0.923150700
0.1,6,0.1,0.1,3,64,0.948597940
0.1,7,0.1,0.1,3,64,0.920518950
0.1,8,0.1,0.1,3,64,0.927358790
0.1,9,0.1,0.1,3,64,0.922139770
0.1,10,0.1,0.1,3,64,0.801881670
0.1,11,0.1,0.1,3,64,0.830576750
0.1,12,0.1,0.1,3,64,0.802170380
0.1,13,0.1,0.1,3,64,0.824984990
0.1,14,0.1,0.1,3,64,0.832618310
0.1,15,0.1,0.1,3,64,0.839179100
0.1,16,0.1,0.1,3,64,0.895598800
0.1,17,0.1,0.1,3,64,0.906956220
0.1,18,0.1,0.1,3,64,0.838542970
0.1,19,0.1,0.1,3,64,0.846211170
0.1,20,0.1,0.1,3,64,0.907252100
0.1,21,0.1,0.1,3,64,0.854385660
0.1,22,0.1,0.1,3,64,0.854195710
0.1,23,0.1,0.1,3,64,0.827668880
0.1,24,0.1,0.1,3,64,0.865845580
0.1,25,0.1,0.1,3,64,0.761163620
0.1,26,0.1,0.1,3,64,0.820795910
0.1,27,0.1,0.1,3,64,0.830614360
0.1,28,0.1,0.1,3,64,0.940655040
0.1,29,0.1,0.1,3,64,0.672838370
0.1,30,0.1,0.1,3,64,0.774291680
0.1,31,0.1,0.1,3,64,0.774896530
0.1,32,0.1,0.1,3,64,0.877612240
0.1,33,0.1,0.1,3,64,0.716595540
0.1,34,0.1,0.1,3,64,0.935447500
0.1,35,0.1,0.1,3,64,0.885206500
0.1,36,0.1,0.1,3,64,0.800079340
0.1,37,0.1,0.1,3,64,0.630465790
0.1,38,0.1,0.1,3,64,0.881762940
0.1,39,0.1,0.1,3,64,0.773222180
0.1,40,0.1,0.1,3,64,0.656098440
0.1,41,0.1,0.1,3,64,0.814163580
0.1,42,0.1,0.1,3,64,0.626264030
0.1,43,0.1,0.1,3,64,0.732504160
0.1,44,0.1,0.1,3,64,0.491745500
0.1,45,0.1,0.1,3,64,0.497948730
0.1,46,0.1,0.1,3,64,0.523537990
0.1,47,0.1,0.1,3,64,0.642194910
0.1,48,0.1,0.1,3,64,0.412229730
0.1,49,0.1,0.1,3,64,0.413406150
0.1,50,0.1,0.1,3,64,0.560959860
0.1,51,0.1,0.1,3,64,0.362286810
0.1,52,0.1,0.1,3,64,0.381470300
0.1,53,0.1,0.1,3,64,0.276694020
0.1,54,0.1,0.1,3,64,0.401344110
0.1,55,0.1,0.1,3,64,0.252096550
0.1,56,0.1,0.1,3,64,0.364087070
0.1,57,0.1,0.1,3,64,0.302311760
0.1,58,0.1,0.1,3,64,0.288389320
0.1,59,0.1,0.1,3,64,0.433970940
0.1,60,0.1,0.1,3,64,0.409013990
0.1,61,0.1,0.1,3,64,0.273315460
0.1,62,0.1,0.1,3,64,0.263934910
0.1,63,0.1,0.1,3,64,0.322798430
0.1,64,0.1,0.1,3,64,0.266605060
0.1,65,0.1,0.1,3,64,0.249621030
0.1,66,0.1,0.1,3,64,0.240988180
0.1,67,0.1,0.1,3,64,0.250000570
0.1,68,0.1,0.1,3,64,0.178555200
0.1,69,0.1,0.1,3,64,0.233032290
0.1,70,0.1,0.1,3,64,0.303470210
0.1,71,0.1,0.1,3,64,0.309559100
0.1,72,0.1,0.1,3,64,0.166860700
0.1,73,0.1,0.1,3,64,0.219558690
0.1,74,0.1,0.1,3,64,0.174558200
0.1,75,0.1,0.1,3,64,0.172437190
0.1,76,0.1,0.1,3,64,0.184512070
0.1,77,0.1,0.1,3,64,0.225211850
0.1,78,0.1,0.1,3,64,0.202899690
0.1,79,0.1,0.1,3,64,0.175458400
0.1,80,0.1,0.1,3,64,0.238828990
0.1,81,0.1,0.1,3,64,0.155878370
0.1,82,0.1,0.1,3,64,0.266486550
0.1,83,0.1,0.1,3,64,0.153875610
0.1,84,0.1,0.1,3,64,0.226260380
0.1,85,0.1,0.1,3,64,0.165195940
0.1,86,0.1,0.1,3,64,0.210707320
0.1,87,0.1,0.1,3,64,0.166134930
0.1,88,0.1,0.1,3,64,0.226463780
0.1,89,0.1,0.1,3,64,0.110751380
0.1,90,0.1,0.1,3,64,0.212925870
0.1,91,0.1,0.1,3,64,0.184775340
0.1,92,0.1,0.1,3,64,0.162214850
0.1,93,0.1,0.1,3,64,0.145409560
0.1,94,0.1,0.1,3,64,0.081953800
0.1,95,0.1,0.1,3,64,0.165697820
0.1,96,0.1,0.1,3,64,0.164941310
0.1,97,0.1,0.1,3,64,0.144067870
0.1,98,0.1,0.1,3,64,0.137718540
0.1,99,0.1,0.1,3,64,0.166166180
0.1,100,0.1,0.1,3,64,0.141880530
