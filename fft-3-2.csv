Learning Rate, Epochs, Sampling Rate, test data fraction, max layers, max neurons, Error
0.1,1,0.1,0.1,3,2,0.959643530
0.1,2,0.1,0.1,3,2,0.943586990
0.1,3,0.1,0.1,3,2,0.927388590
0.1,4,0.1,0.1,3,2,0.919929990
0.1,5,0.1,0.1,3,2,0.913070490
0.1,6,0.1,0.1,3,2,0.916743150
0.1,7,0.1,0.1,3,2,0.920229780
0.1,8,0.1,0.1,3,2,0.911539180
0.1,9,0.1,0.1,3,2,0.918291630
0.1,10,0.1,0.1,3,2,0.912967170
0.1,11,0.1,0.1,3,2,0.896186010
0.1,12,0.1,0.1,3,2,0.901111940
0.1,13,0.1,0.1,3,2,0.886231110
0.1,14,0.1,0.1,3,2,0.906731130
0.1,15,0.1,0.1,3,2,0.904841490
0.1,16,0.1,0.1,3,2,0.905366000
0.1,17,0.1,0.1,3,2,0.833430140
0.1,18,0.1,0.1,3,2,0.789900910
0.1,19,0.1,0.1,3,2,0.780084170
0.1,20,0.1,0.1,3,2,0.882731130
0.1,21,0.1,0.1,3,2,0.794096230
0.1,22,0.1,0.1,3,2,0.844406250
0.1,23,0.1,0.1,3,2,0.761992040
0.1,24,0.1,0.1,3,2,0.869157250
0.1,25,0.1,0.1,3,2,0.843357450
0.1,26,0.1,0.1,3,2,0.897683510
0.1,27,0.1,0.1,3,2,0.816691180
0.1,28,0.1,0.1,3,2,0.815409050
0.1,29,0.1,0.1,3,2,0.937033440
0.1,30,0.1,0.1,3,2,0.797137830
0.1,31,0.1,0.1,3,2,0.875187480
0.1,32,0.1,0.1,3,2,0.845364230
0.1,33,0.1,0.1,3,2,0.868104090
0.1,34,0.1,0.1,3,2,0.782914150
0.1,35,0.1,0.1,3,2,0.798249570
0.1,36,0.1,0.1,3,2,0.791416520
0.1,37,0.1,0.1,3,2,0.705030530
0.1,38,0.1,0.1,3,2,0.810170470
0.1,39,0.1,0.1,3,2,0.623097960
0.1,40,0.1,0.1,3,2,0.792362230
0.1,41,0.1,0.1,3,2,0.695955530
0.1,42,0.1,0.1,3,2,0.739519050
0.1,43,0.1,0.1,3,2,0.755979820
0.1,44,0.1,0.1,3,2,0.697681450
0.1,45,0.1,0.1,3,2,0.690024490
0.1,46,0.1,0.1,3,2,0.940401800
0.1,47,0.1,0.1,3,2,0.963385780
0.1,48,0.1,0.1,3,2,0.744916760
0.1,49,0.1,0.1,3,2,0.651141230
0.1,50,0.1,0.1,3,2,0.655780810
0.1,51,0.1,0.1,3,2,0.640601360
0.1,52,0.1,0.1,3,2,0.730306990
0.1,53,0.1,0.1,3,2,0.708109140
0.1,54,0.1,0.1,3,2,0.678306800
0.1,55,0.1,0.1,3,2,0.608547470
0.1,56,0.1,0.1,3,2,0.644132500
0.1,57,0.1,0.1,3,2,0.662791800
0.1,58,0.1,0.1,3,2,0.728537930
0.1,59,0.1,0.1,3,2,0.708942040
0.1,60,0.1,0.1,3,2,0.620997690
0.1,61,0.1,0.1,3,2,0.633730250
0.1,62,0.1,0.1,3,2,0.669565930
0.1,63,0.1,0.1,3,2,0.612591700
0.1,64,0.1,0.1,3,2,0.676971340
0.1,65,0.1,0.1,3,2,0.661647870
0.1,66,0.1,0.1,3,2,0.646065990
0.1,67,0.1,0.1,3,2,0.580650190
0.1,68,0.1,0.1,3,2,0.717401850
0.1,69,0.1,0.1,3,2,0.716178900
0.1,70,0.1,0.1,3,2,0.603507690
0.1,71,0.1,0.1,3,2,0.626181680
0.1,72,0.1,0.1,3,2,0.632439650
0.1,73,0.1,0.1,3,2,0.594713000
0.1,74,0.1,0.1,3,2,0.626414490
0.1,75,0.1,0.1,3,2,0.604396660
0.1,76,0.1,0.1,3,2,0.598558500
0.1,77,0.1,0.1,3,2,0.588029000
0.1,78,0.1,0.1,3,2,0.593960650
0.1,79,0.1,0.1,3,2,0.568390350
0.1,80,0.1,0.1,3,2,0.596203140
0.1,81,0.1,0.1,3,2,0.615629740
0.1,82,0.1,0.1,3,2,0.619505590
0.1,83,0.1,0.1,3,2,0.606658120
0.1,84,0.1,0.1,3,2,0.586371830
0.1,85,0.1,0.1,3,2,0.614306300
0.1,86,0.1,0.1,3,2,0.597444370
0.1,87,0.1,0.1,3,2,0.580741300
0.1,88,0.1,0.1,3,2,0.609225170
0.1,89,0.1,0.1,3,2,0.593321160
0.1,90,0.1,0.1,3,2,0.584103600
0.1,91,0.1,0.1,3,2,0.570116870
0.1,92,0.1,0.1,3,2,0.573375690
0.1,93,0.1,0.1,3,2,0.606019460
0.1,94,0.1,0.1,3,2,0.612196440
0.1,95,0.1,0.1,3,2,0.588512020
0.1,96,0.1,0.1,3,2,0.619627510
0.1,97,0.1,0.1,3,2,0.636668840
0.1,98,0.1,0.1,3,2,0.633148250
0.1,99,0.1,0.1,3,2,0.620688970
0.1,100,0.1,0.1,3,2,0.624177130
